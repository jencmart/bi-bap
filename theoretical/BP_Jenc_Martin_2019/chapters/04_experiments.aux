\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {3}Experiments}{53}{chapter.3}}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{chapterexperiments}{{\M@TitleReference {3}{Experiments}}{53}{Experiments}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Data set generator}{53}{section.3.1}}
\newlabel{generate:linear:model}{{\M@TitleReference {38}{Data set generator}}{53}{Generate clean data}{defi.38}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Generating outliers}{54}{subsection.3.1.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Different types of outliers. }}{54}{figure.3.1}}
\newlabel{outliers:types:figure}{{\M@TitleReference {3.1}{Different types of outliers. }}{54}{Different types of outliers. }{figure.3.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Data sets}{55}{section.3.2}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Implementation of the algorithms}{56}{section.3.3}}
\citation{numpy}
\citation{eigenweb}
\citation{pybind11}
\citation{scikit-learn}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Results}{58}{section.3.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}The strong necessary condition algorithms}{58}{subsection.3.4.1}}
\newlabel{strong:experiments}{{\M@TitleReference {3.4.1}{The strong necessary condition algorithms}}{58}{The strong necessary condition algorithms}{subsection.3.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Algorithms for finding the exact solution}{58}{subsection.3.4.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Similarity of the solutions given by the algorithms finding $h$-element subsets satisfying strong necessary condition compared to the OLS solution on the subset of the data set that does not contain outliers. On the left are two box plots for all algorithms. Since the visualization is influenced by the scale of MMEA-I and MOEA-I box plots, we provide also two graphs without these two algorithms on the right.}}{59}{figure.3.2}}
\newlabel{all_distances}{{\M@TitleReference {3.2}{Similarity of the solutions given by the algorithms finding $h$-element subsets satisfying strong necessary condition compared to the OLS solution on the subset of the data set that does not contain outliers. On the left are two box plots for all algorithms. Since the visualization is influenced by the scale of MMEA-I and MOEA-I box plots, we provide also two graphs without these two algorithms on the right.}}{59}{Similarity of the solutions given by the algorithms finding $h$-element subsets satisfying strong necessary condition compared to the OLS solution on the subset of the data set that does not contain outliers. On the left are two box plots for all algorithms. Since the visualization is influenced by the scale of MMEA-I and MOEA-I box plots, we provide also two graphs without these two algorithms on the right}{figure.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces For various combinations of parameters $n$ and $p$ we calculated average multiplicative improvement of the CPU time for running FSA-QR-BAB and FSA-QR-BSA instead of BAB and BSA.}}{60}{figure.3.3}}
\newlabel{exact:improvement}{{\M@TitleReference {3.3}{For various combinations of parameters $n$ and $p$ we calculated average multiplicative improvement of the CPU time for running FSA-QR-BAB and FSA-QR-BSA instead of BAB and BSA.}}{60}{For various combinations of parameters $n$ and $p$ we calculated average multiplicative improvement of the CPU time for running FSA-QR-BAB and FSA-QR-BSA instead of BAB and BSA}{figure.3.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Average, minimum and maximum CPU times of computation time for BSA for $p=2$ and various combinations of parameters $n$ and $out$ for each dataset.}}{60}{table.3.1}}
\newlabel{bsa:big:table}{{\M@TitleReference {3.1}{Average, minimum and maximum CPU times of computation time for BSA for $p=2$ and various combinations of parameters $n$ and $out$ for each dataset.}}{60}{Average, minimum and maximum CPU times of computation time for BSA for $p=2$ and various combinations of parameters $n$ and $out$ for each dataset}{table.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.3}FAST-LTS and combinations of the algorithms}{60}{subsection.3.4.3}}
\newlabel{results:combinations}{{\M@TitleReference {3.4.3}{FAST-LTS and combinations of the algorithms}}{60}{FAST-LTS and combinations of the algorithms}{subsection.3.4.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.2}{\ignorespaces Percentage of the $h$-elements subsets provided by FAST-LTS which did not satisfied strong necessary condition, and the MMEA-QR and MOEA-QR were able to improve them.}}{61}{table.3.2}}
\newlabel{table:percentage:improvement}{{\M@TitleReference {3.2}{Percentage of the $h$-elements subsets provided by FAST-LTS which did not satisfied strong necessary condition, and the MMEA-QR and MOEA-QR were able to improve them.}}{61}{Percentage of the $h$-elements subsets provided by FAST-LTS which did not satisfied strong necessary condition, and the MMEA-QR and MOEA-QR were able to improve them}{table.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.4}Random algorithm and RBSA}{61}{subsection.3.4.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Cosine similarity and $L^2$ norm for multiple algorithms. Random algorithms are outperformed by the algorithms finding the weak and strong necessary conditions.}}{62}{figure.3.4}}
\newlabel{randim:box}{{\M@TitleReference {3.4}{Cosine similarity and $L^2$ norm for multiple algorithms. Random algorithms are outperformed by the algorithms finding the weak and strong necessary conditions.}}{62}{Cosine similarity and $L^2$ norm for multiple algorithms. Random algorithms are outperformed by the algorithms finding the weak and strong necessary conditions}{figure.3.4}{}}
\@setckpt{chapters/04_experiments}{
\setcounter{page}{63}
\setcounter{equation}{0}
\setcounter{enumi}{5}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{2}
\setcounter{mpfootnote}{0}
\setcounter{@memmarkcntra}{0}
\setcounter{storedpagenumber}{1}
\setcounter{book}{0}
\setcounter{part}{0}
\setcounter{chapter}{3}
\setcounter{section}{4}
\setcounter{subsection}{4}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{@ppsavesec}{0}
\setcounter{@ppsaveapp}{0}
\setcounter{vslineno}{0}
\setcounter{poemline}{0}
\setcounter{modulo@vs}{0}
\setcounter{memfvsline}{0}
\setcounter{verse}{0}
\setcounter{chrsinstr}{0}
\setcounter{poem}{0}
\setcounter{newflo@tctr}{4}
\setcounter{@contsubnum}{0}
\setcounter{maxsecnumdepth}{3}
\setcounter{sidefootnote}{0}
\setcounter{pagenote}{0}
\setcounter{pagenoteshadow}{0}
\setcounter{memfbvline}{0}
\setcounter{bvlinectr}{0}
\setcounter{cp@cntr}{0}
\setcounter{ism@mctr}{0}
\setcounter{xsm@mctr}{0}
\setcounter{csm@mctr}{0}
\setcounter{ksm@mctr}{0}
\setcounter{xksm@mctr}{0}
\setcounter{cksm@mctr}{0}
\setcounter{msm@mctr}{0}
\setcounter{xmsm@mctr}{0}
\setcounter{cmsm@mctr}{0}
\setcounter{bsm@mctr}{0}
\setcounter{workm@mctr}{0}
\setcounter{sheetsequence}{79}
\setcounter{lastsheet}{99}
\setcounter{lastpage}{83}
\setcounter{figure}{4}
\setcounter{lofdepth}{1}
\setcounter{table}{2}
\setcounter{lotdepth}{1}
\setcounter{Item}{28}
\setcounter{Hfootnote}{2}
\setcounter{memhycontfloat}{0}
\setcounter{Hpagenote}{0}
\setcounter{bookmark@seq@number}{47}
\setcounter{@todonotes@numberoftodonotes}{4}
\setcounter{parentequation}{0}
\setcounter{AlgoLine}{1}
\setcounter{algocfline}{8}
\setcounter{algocfproc}{8}
\setcounter{algocf}{8}
\setcounter{defi}{38}
\setcounter{cvi}{0}
\setcounter{cvi*}{0}
\setcounter{section@level}{2}
}
